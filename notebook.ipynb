{"cells":[{"source":"![](image.jpg)\n\n\nDive into the heart of data science with a project that combines healthcare insights and predictive analytics. As a Data Scientist at a top Health Insurance company, you have the opportunity to predict customer healthcare costs using the power of machine learning. Your insights will help tailor services and guide customers in planning their healthcare expenses more effectively.\n\n## Dataset Summary\n\nMeet your primary tool: the `insurance.csv` dataset. Packed with information on health insurance customers, this dataset is your key to unlocking patterns in healthcare costs. Here's what you need to know about the data you'll be working with:\n\n## insurance.csv\n| Column    | Data Type | Description                                                      |\n|-----------|-----------|------------------------------------------------------------------|\n| `age`       | int       | Age of the primary beneficiary.                                  |\n| `sex`       | object    | Gender of the insurance contractor (male or female).             |\n| `bmi`       | float     | Body mass index, a key indicator of body fat based on height and weight. |\n| `children`  | int       | Number of dependents covered by the insurance plan.              |\n| `smoker`    | object    | Indicates whether the beneficiary smokes (yes or no).            |\n| `region`    | object    | The beneficiary's residential area in the US, divided into four regions. |\n| `charges`   | float     | Individual medical costs billed by health insurance.             |\n\n\n\nA bit of data cleaning is key to ensure the dataset is ready for modeling. Once your model is built using the `insurance.csv` dataset, the next step is to apply it to the `validation_dataset.csv`. This new dataset, similar to your training data minus the `charges` column, tests your model's accuracy and real-world utility by predicting costs for new customers.\n\n## Let's Get Started!\n\nThis project is your playground for applying data science in a meaningful way, offering insights that have real-world applications. Ready to explore the data and uncover insights that could revolutionize healthcare planning? Let's begin this exciting journey!","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"6918e18a-c248-4929-b552-7aee2057c0eb","cell_type":"markdown"},{"source":"# Re-run this cell\n# Import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n# Loading the insurance dataset\ninsurance_data_path = 'insurance.csv'\ninsurance = pd.read_csv(insurance_data_path)\nprint(insurance.head())\nprint(insurance.shape)","metadata":{"executionCancelledAt":null,"executionTime":29,"lastExecutedAt":1757968761334,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Re-run this cell\n# Import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n# Loading the insurance dataset\ninsurance_data_path = 'insurance.csv'\ninsurance = pd.read_csv(insurance_data_path)\nprint(insurance.head())\nprint(insurance.shape)","outputsMetadata":{"0":{"height":164,"type":"stream"}},"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f"},"id":"81a07c66-a3d4-4fdd-9c3c-7b3a19b80d62","cell_type":"code","execution_count":297,"outputs":[{"output_type":"stream","name":"stdout","text":"    age     sex     bmi  children smoker     region       charges\n0  19.0  female  27.900       0.0    yes  southwest     16884.924\n1  18.0    male  33.770       1.0     no  Southeast     1725.5523\n2  28.0    male  33.000       3.0     no  southeast     $4449.462\n3  33.0    male  22.705       0.0     no  northwest  $21984.47061\n4  32.0    male  28.880       0.0     no  northwest    $3866.8552\n(1338, 7)\n"}]},{"source":"## Data Cleaning\n### 1.1 dealing with missing data\nFirstly detect wheather there is any:","metadata":{},"cell_type":"markdown","id":"255af574-ebf0-4c5a-8853-1185810615d5"},{"source":"print(insurance.isna().sum().sort_values())","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1757968761386,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(insurance.isna().sum().sort_values())","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"id":"a143c3b2-1ff1-47a0-8fc6-662b8b19dbf1","cell_type":"code","execution_count":298,"outputs":[{"output_type":"stream","name":"stdout","text":"charges     54\nage         66\nsex         66\nbmi         66\nchildren    66\nsmoker      66\nregion      66\ndtype: int64\n"}]},{"source":"Dealing with it:","metadata":{},"cell_type":"markdown","id":"20623bd0-7028-4903-8b65-4f625f408833"},{"source":"#Creating two imputers to fit data types well \nCategorical_imputer = SimpleImputer(strategy = 'most_frequent')\nNumerical_imputer = SimpleImputer(strategy = 'median')\n#Defining columns before using\nNum_columns = ['age','bmi','children']\nCat_columns = ['sex','smoker','region']\n#Imputing the missing values\ninsurance[Num_columns] = Numerical_imputer.fit_transform(insurance[Num_columns]) \ninsurance[Cat_columns] = Categorical_imputer.fit_transform(insurance[Cat_columns]) \n#Dropping the rows of missing target to avoid bias or miscalculations\ninsurance['charges'] = insurance['charges'].replace('[\\$,]', '', regex=True).astype(float)\ninsurance = insurance.dropna(subset = ['charges'])\ninsurance = insurance.reset_index(drop=True)\n#Printing to see The changes and wheather all NaNs are gone or not\nprint(insurance)\nprint(insurance.isna().sum().sort_values())","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1757968761445,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Creating two imputers to fit data types well \nCategorical_imputer = SimpleImputer(strategy = 'most_frequent')\nNumerical_imputer = SimpleImputer(strategy = 'median')\n#Defining columns before using\nNum_columns = ['age','bmi','children']\nCat_columns = ['sex','smoker','region']\n#Imputing the missing values\ninsurance[Num_columns] = Numerical_imputer.fit_transform(insurance[Num_columns]) \ninsurance[Cat_columns] = Categorical_imputer.fit_transform(insurance[Cat_columns]) \n#Dropping the rows of missing target to avoid bias or miscalculations\ninsurance['charges'] = insurance['charges'].replace('[\\$,]', '', regex=True).astype(float)\ninsurance = insurance.dropna(subset = ['charges'])\ninsurance = insurance.reset_index(drop=True)\n#Printing to see The changes and wheather all NaNs are gone or not\nprint(insurance)\nprint(insurance.isna().sum().sort_values())","outputsMetadata":{"0":{"height":479,"type":"stream"}}},"cell_type":"code","id":"a85723cc-3fe1-4294-b482-c0e094ca75a0","outputs":[{"output_type":"stream","name":"stdout","text":"       age     sex     bmi  children smoker     region      charges\n0     19.0  female  27.900       0.0    yes  southwest  16884.92400\n1     18.0    male  33.770       1.0     no  Southeast   1725.55230\n2     28.0    male  33.000       3.0     no  southeast   4449.46200\n3     33.0    male  22.705       0.0     no  northwest  21984.47061\n4     32.0    male  28.880       0.0     no  northwest   3866.85520\n...    ...     ...     ...       ...    ...        ...          ...\n1267  50.0    male  30.970       3.0     no  Northwest  10600.54830\n1268 -18.0  female  31.920       0.0     no  Northeast   2205.98080\n1269  18.0  female  36.850       0.0     no  southeast   1629.83350\n1270  21.0  female  25.800       0.0     no  southwest   2007.94500\n1271  61.0  female  29.070       0.0    yes  northwest  29141.36030\n\n[1272 rows x 7 columns]\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n"}],"execution_count":299},{"source":"### 1.2 Dealing with catagorical Data","metadata":{},"cell_type":"markdown","id":"e53f69f3-c937-4fb8-9270-63eaa3090683"},{"source":"#Using One-Hot Endcoding to encode to encode catagorical data to numeric\ninsurance['region'] = insurance['region'].str.lower()\ninsurance['smoker'] = insurance['smoker'].str.lower()\ninsurance = pd.get_dummies(insurance, columns=['smoker','region'], drop_first=True)\n#Sex will be handeled independently as it has many variations of the same meaning so to remove confusion\ninsurance['sex'] = insurance['sex'].str.lower().map({'male': 1, 'm': 1, 'man': 1, 'female': 0, 'f': 0, 'woman': 0})\n\ninsurance.head()","metadata":{"executionCancelledAt":null,"executionTime":57,"lastExecutedAt":1757968761502,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Using One-Hot Endcoding to encode to encode catagorical data to numeric\ninsurance['region'] = insurance['region'].str.lower()\ninsurance['smoker'] = insurance['smoker'].str.lower()\ninsurance = pd.get_dummies(insurance, columns=['smoker','region'], drop_first=True)\n#Sex will be handeled independently as it has many variations of the same meaning so to remove confusion\ninsurance['sex'] = insurance['sex'].str.lower().map({'male': 1, 'm': 1, 'man': 1, 'female': 0, 'f': 0, 'woman': 0})\n\ninsurance.head()","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"de6b4f8c-e0c6-495a-9c4e-5818af31f32f","nodeType":"const"}}},"1":{"height":500,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"43d28b3b-eed0-45f3-864f-1166a366e861","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"age","type":"number"},{"name":"sex","type":"integer"},{"name":"bmi","type":"number"},{"name":"children","type":"number"},{"name":"charges","type":"number"},{"name":"smoker_yes","type":"integer"},{"name":"region_northwest","type":"integer"},{"name":"region_southeast","type":"integer"},{"name":"region_southwest","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"age":[19,18,28,33,32],"sex":[0,1,1,1,1],"bmi":[27.9,33.77,33,22.705,28.88],"children":[0,1,3,0,0],"charges":[16884.924,1725.5523,4449.462,21984.47061,3866.8552],"smoker_yes":[1,0,0,0,0],"region_northwest":[0,0,0,1,1],"region_southeast":[0,1,1,0,0],"region_southwest":[1,0,0,0,0]}},"total_rows":5,"truncation_type":null},"text/plain":"    age  sex     bmi  ...  region_northwest  region_southeast  region_southwest\n0  19.0    0  27.900  ...                 0                 0                 1\n1  18.0    1  33.770  ...                 0                 1                 0\n2  28.0    1  33.000  ...                 0                 1                 0\n3  33.0    1  22.705  ...                 1                 0                 0\n4  32.0    1  28.880  ...                 1                 0                 0\n\n[5 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>charges</th>\n      <th>smoker_yes</th>\n      <th>region_northwest</th>\n      <th>region_southeast</th>\n      <th>region_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19.0</td>\n      <td>0</td>\n      <td>27.900</td>\n      <td>0.0</td>\n      <td>16884.92400</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18.0</td>\n      <td>1</td>\n      <td>33.770</td>\n      <td>1.0</td>\n      <td>1725.55230</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.0</td>\n      <td>1</td>\n      <td>33.000</td>\n      <td>3.0</td>\n      <td>4449.46200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33.0</td>\n      <td>1</td>\n      <td>22.705</td>\n      <td>0.0</td>\n      <td>21984.47061</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32.0</td>\n      <td>1</td>\n      <td>28.880</td>\n      <td>0.0</td>\n      <td>3866.85520</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":300}],"execution_count":300},{"source":"The data appeared to be cofusing as: Sex had many variations for the same values such as male, man, m to represent the male. While the case sensetivity in region made it detect some regions a multiple times in the One-Hot encoder. But I delt with each columns problem solely correctly, plus unifying the form of Charges to remove the $ included in some only to be able to get it ready for modelling.","metadata":{},"cell_type":"markdown","id":"0690b2f5-fc7e-44ba-ab13-8a32abffd711"},{"source":"### 1.3 Data splitting and scaling","metadata":{},"cell_type":"markdown","id":"0292d081-8238-4856-af49-865ba1446af2"},{"source":"#Data splitting\nX = insurance.drop(\"charges\", axis = 1)\ny = insurance[\"charges\"]\n#Data scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1757968761561,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Data splitting\nX = insurance.drop(\"charges\", axis = 1)\ny = insurance[\"charges\"]\n#Data scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"bb7ea689-db06-41ae-8d38-98c2e8fae028","outputs":[],"execution_count":301},{"source":"## 2. Model **Creation**","metadata":{},"cell_type":"markdown","id":"f0f7d4fc-8e37-49d3-9c68-347a2647c36f"},{"source":"### 2.1 Model **intiation**","metadata":{},"cell_type":"markdown","id":"d1d1fb1c-a65e-418f-abc0-90cd5fee941b"},{"source":"#Using ridge as it is good for few features with regularization to decrease the effect of some if needed\nridge = Ridge()\nmodel = GridSearchCV(ridge,param_grid = {'alpha': [0.0001,0.001,0.01,0.1,1,10,100,1000,10000]}, cv=5, scoring='r2')\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 39)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nr2_score = r2_score(y_test,y_pred)\nprint(r2_score)\nprint(model.best_params_)","metadata":{"executionCancelledAt":null,"executionTime":176,"lastExecutedAt":1757968761739,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Using ridge as it is good for few features with regularization to decrease the effect of some if needed\nridge = Ridge()\nmodel = GridSearchCV(ridge,param_grid = {'alpha': [0.0001,0.001,0.01,0.1,1,10,100,1000,10000]}, cv=5, scoring='r2')\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 39)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nr2_score = r2_score(y_test,y_pred)\nprint(r2_score)\nprint(model.best_params_)"},"cell_type":"code","id":"8abf062f-c171-4593-9724-a1a70a3aa0d3","outputs":[{"output_type":"stream","name":"stdout","text":"0.6852741689959847\n{'alpha': 1}\n"}],"execution_count":302},{"source":"### 2.2 Predicting the new Charges","metadata":{},"cell_type":"markdown","id":"02db9251-af80-40e3-b1ea-ae029549df53"},{"source":"Importing and viewing the data","metadata":{},"cell_type":"markdown","id":"92ae9043-bb1b-484e-a00c-eb1433519e0b"},{"source":"validation_data = pd.read_csv('validation_dataset.csv')\nprint(validation_data)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1757968761790,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"validation_data = pd.read_csv('validation_dataset.csv')\nprint(validation_data)"},"cell_type":"code","id":"fdabd180-c35a-440d-8db5-208e636b880d","outputs":[{"output_type":"stream","name":"stdout","text":"     age     sex        bmi  children smoker     region\n0   18.0  female  24.090000       1.0     no  southeast\n1   39.0    male  26.410000       0.0    yes  northeast\n2   27.0    male  29.150000       0.0    yes  southeast\n3   71.0    male  65.502135      13.0    yes  southeast\n4   28.0    male  38.060000       0.0     no  southeast\n5   70.0  female  72.958351      11.0    yes  southeast\n6   29.0  female  32.110000       2.0     no  northwest\n7   42.0  female  41.325000       1.0     no  northeast\n8   48.0  female  36.575000       0.0     no  northwest\n9   63.0    male  33.660000       3.0     no  southeast\n10  27.0    male  18.905000       3.0     no  northeast\n11  51.0  female  36.670000       2.0     no  northwest\n12  60.0  female  24.530000       0.0     no  southeast\n13  57.0  female  28.700000       0.0     no  southwest\n14  20.0  female  28.975000       0.0     no  northwest\n15  18.0    male  30.400000       3.0     no  northeast\n16  83.0    male  89.097296       9.0     no  northwest\n17  92.0  female  69.127267      13.0    yes  southeast\n18  84.0  female  75.742693       2.0    yes  southwest\n19  55.0  female  26.980000       0.0     no  northwest\n20  23.0    male  18.715000       0.0     no  northwest\n21  49.0  female  33.345000       2.0     no  northeast\n22  33.0  female  35.530000       0.0    yes  northwest\n23  47.0  female  36.000000       1.0     no  southwest\n24  40.0    male  32.300000       2.0     no  northwest\n25  21.0  female  35.720000       0.0     no  northwest\n26  74.0  female  65.454749      13.0    yes  northeast\n27  28.0  female  25.800000       0.0     no  southwest\n28  57.0  female  25.740000       2.0     no  southeast\n29  45.0    male  33.700000       1.0     no  southwest\n30  27.0  female  32.395000       1.0     no  northeast\n31  19.0  female  33.110000       0.0    yes  southeast\n32  44.0  female  20.235000       1.0    yes  northeast\n33  63.0  female  26.220000       0.0     no  northwest\n34  43.0  female  24.700000       2.0    yes  northwest\n35  46.0    male  40.375000       2.0     no  northwest\n36  78.0    male  66.370173      11.0    yes  northwest\n37  52.0    male  38.600000       2.0     no  southwest\n38  18.0    male  21.780000       2.0     no  southeast\n39  70.0    male  60.617535      10.0     no  southeast\n40  29.0    male  34.400000       0.0    yes  southwest\n41  35.0    male  39.710000       4.0     no  northeast\n42  29.0    male  27.200000       0.0     no  southwest\n43  89.0    male  68.736874       6.0    yes  northwest\n44  26.0    male  32.490000       1.0     no  northeast\n45  58.0    male  36.955000       2.0    yes  northwest\n46  92.0    male  84.973279      11.0    yes  southwest\n47  19.0    male  44.880000       0.0    yes  southeast\n48  61.0    male  33.915000       0.0     no  northeast\n49  44.0  female  38.060000       0.0    yes  southeast\n"}],"execution_count":303},{"source":"#Applying the same changes to be able to use the features to predict\nvalidation_data['region'] = validation_data['region'].str.lower()\nvalidation_data['smoker'] = validation_data['smoker'].str.lower()\nvalidation_data = pd.get_dummies(validation_data, columns=['smoker','region'], drop_first=True)\nvalidation_data['sex'] = validation_data['sex'].str.lower().map({'male': 1, 'm': 1, 'man': 1, 'female': 0, 'f': 0, 'woman': 0})","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1757968761845,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Applying the same changes to be able to use the features to predict\nvalidation_data['region'] = validation_data['region'].str.lower()\nvalidation_data['smoker'] = validation_data['smoker'].str.lower()\nvalidation_data = pd.get_dummies(validation_data, columns=['smoker','region'], drop_first=True)\nvalidation_data['sex'] = validation_data['sex'].str.lower().map({'male': 1, 'm': 1, 'man': 1, 'female': 0, 'f': 0, 'woman': 0})","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"9b9b49fc-05d0-4d5e-904e-28da5cf35ddf","outputs":[],"execution_count":304},{"source":"#Predicting charges\nvalidation_data['predicted_charges'] = model.predict(validation_data)\nprint(validation_data)","metadata":{"executionCancelledAt":null,"executionTime":64,"lastExecutedAt":1757968761910,"lastExecutedByKernel":"0f12c03c-93ef-4f78-bcff-2ecab8b4864f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Predicting charges\nvalidation_data['predicted_charges'] = model.predict(validation_data)\nprint(validation_data)"},"cell_type":"code","id":"c0ac12c5-5fcd-440a-93f3-7773b3b61d3c","outputs":[{"output_type":"stream","name":"stdout","text":"     age  sex        bmi  ...  region_southeast  region_southwest  predicted_charges\n0   18.0    0  24.090000  ...                 1                 0        4244.742170\n1   39.0    1  26.410000  ...                 0                 0       30511.951539\n2   27.0    1  29.150000  ...                 1                 0       29450.053520\n3   71.0    1  65.502135  ...                 1                 0       51829.768169\n4   28.0    1  38.060000  ...                 1                 0        9400.920067\n5   70.0    0  72.958351  ...                 1                 0       53931.873453\n6   29.0    0  32.110000  ...                 0                 0        9538.707739\n7   42.0    0  41.325000  ...                 0                 0       13553.470057\n8   48.0    0  36.575000  ...                 0                 0       12048.929454\n9   63.0    1  33.660000  ...                 1                 0       12255.032270\n10  27.0    1  18.905000  ...                 0                 0        4633.466296\n11  51.0    0  36.670000  ...                 0                 0       13179.633183\n12  60.0    0  24.530000  ...                 1                 0        7825.030867\n13  57.0    0  28.700000  ...                 0                 1        9746.612806\n14  20.0    0  28.975000  ...                 0                 0        6771.899027\n15  18.0    1  30.400000  ...                 0                 0        7927.241348\n16  83.0    1  89.097296  ...                 0                 0       37403.771441\n17  92.0    0  69.127267  ...                 1                 0       55391.487091\n18  84.0    0  75.742693  ...                 0                 1       53206.593945\n19  55.0    0  26.980000  ...                 0                 0        9252.803417\n20  23.0    1  18.715000  ...                 0                 0        3025.753379\n21  49.0    0  33.345000  ...                 0                 0       11746.949797\n22  33.0    0  35.530000  ...                 0                 0       33635.793906\n23  47.0    0  36.000000  ...                 0                 1       11858.636025\n24  40.0    1  32.300000  ...                 0                 0       10264.138699\n25  21.0    0  35.720000  ...                 0                 0        9278.000761\n26  74.0    0  65.454749  ...                 0                 0       53380.834173\n27  28.0    0  25.800000  ...                 0                 1        6060.963533\n28  57.0    0  25.740000  ...                 1                 0        8807.182377\n29  45.0    1  33.700000  ...                 0                 1       10505.841404\n30  27.0    0  32.395000  ...                 0                 0        8987.047505\n31  19.0    0  33.110000  ...                 1                 0       30484.254781\n32  44.0    0  20.235000  ...                 0                 0       29515.849048\n33  63.0    0  26.220000  ...                 0                 0        9711.030685\n34  43.0    0  24.700000  ...                 0                 0       31494.211506\n35  46.0    1  40.375000  ...                 0                 0       13702.849742\n36  78.0    1  66.370173  ...                 0                 0       52963.829795\n37  52.0    1  38.600000  ...                 0                 1       13310.555710\n38  18.0    1  21.780000  ...                 1                 0        3482.358466\n39  70.0    1  60.617535  ...                 1                 0       25425.145536\n40  29.0    1  34.400000  ...                 0                 1       32214.740991\n41  35.0    1  39.710000  ...                 0                 0       13223.700709\n42  29.0    1  27.200000  ...                 0                 1        6306.694335\n43  89.0    1  68.736874  ...                 0                 0       52758.275838\n44  26.0    1  32.490000  ...                 0                 0        8582.988906\n45  58.0    1  36.955000  ...                 0                 0       36904.254095\n46  92.0    1  84.973279  ...                 0                 1       60597.524259\n47  19.0    1  44.880000  ...                 1                 0       34351.312390\n48  61.0    1  33.915000  ...                 0                 0       11876.893578\n49  44.0    0  38.060000  ...                 1                 0       34538.675647\n\n[50 rows x 9 columns]\n"}],"execution_count":305}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}